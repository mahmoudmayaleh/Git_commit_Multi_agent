# ğŸš€ GETTING STARTED

Welcome to the Git Commit Writer Pipeline! This guide will get you up and running in minutes.

## âš¡ Quick Start (5 Minutes)

### Step 1: Install Dependencies

```powershell
pip install -r requirements.txt
```

### Step 2: Configure

```powershell
copy .env.example .env
notepad .env
```

**Minimal Configuration for Local Inference:**

```env
LLM_MODE=local
DEVICE=cuda
DEBUG_MODE=true
```

**Or for API Mode (if you have OpenChat-3.5 running):**

```env
LLM_MODE=api
API_BASE_URL=http://localhost:8000/v1
DEBUG_MODE=true
```

### Step 3: Verify Setup

```powershell
python quickstart.py
```

### Step 4: Try the Example

```powershell
python tests/example_usage.py
```

This creates a test repository and demonstrates the full pipeline.

### Step 5: Use with Your Code

```powershell
# In your Git repository
git add .
python main.py
```

That's it! ğŸ‰

---

## ğŸ“‹ What You Need

### Required

- âœ… Python 3.8 or higher
- âœ… Git CLI installed
- âœ… 8GB+ RAM

### For Local Inference (Recommended)

- âœ… CUDA-capable GPU with 8GB+ VRAM
- âœ… Or 16GB+ RAM for CPU inference

### For API Mode (Alternative)

- âœ… OpenChat-3.5 API endpoint
- âœ… Or vLLM/text-generation-inference server

---

## ğŸ¯ Choose Your Setup

### Option A: Local Inference (Best Quality)

**Pros:**

- No external dependencies
- Complete privacy
- No API costs

**Cons:**

- Requires GPU or takes longer on CPU
- Larger download (~7GB model)

**Setup:**

```powershell
# Install PyTorch with CUDA
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Install other dependencies
pip install -r requirements.txt

# Configure
copy .env.example .env
# Set LLM_MODE=local in .env
```

**First Run:**
The model will download automatically on first use (~7GB, 5-10 minutes).

### Option B: API Mode (Fastest)

**Pros:**

- Very fast inference
- Minimal local resources
- Shared model across projects

**Cons:**

- Requires running API server
- Network dependency

**Setup with vLLM:**

```powershell
# Install vLLM
pip install vllm

# Start server (in separate terminal)
vllm serve openchat/openchat-3.5-0106 --port 8000

# Configure
copy .env.example .env
# Set LLM_MODE=api in .env
```

---

## ğŸ” What Happens When You Run

```
python main.py
```

1. **Checks** for staged Git changes
2. **DiffAgent** parses the diff into bullet points
3. **SummaryAgent** creates a concise summary
4. **CommitWriterAgent** generates the commit message
5. **Shows** you the message and asks to commit

Example Output:

```
====================================================================
   ğŸ¤– Git Commit Writer Pipeline - Powered by OpenChat-3.5
====================================================================

Initializing pipeline...
âœ“ Pipeline initialized

Checking for staged changes...
âœ“ Found staged changes

Running pipeline...

====================================================================
  ğŸ“ GENERATED COMMIT MESSAGE
====================================================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ feat(api): implement user authentication system                â”‚
â”‚                                                                 â”‚
â”‚ - Add JWT token generation and validation                      â”‚
â”‚ - Implement password hashing with bcrypt                       â”‚
â”‚ - Create login and logout endpoints                            â”‚
â”‚ - Add middleware for route protection                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Do you want to commit with this message? (y/n):
```

---

## ğŸ“š Documentation Guide

| Document                 | Purpose                                      |
| ------------------------ | -------------------------------------------- |
| **README.md**            | Project overview, installation, architecture |
| **USAGE.md**             | Detailed usage guide, all CLI options        |
| **TROUBLESHOOTING.md**   | Common issues and solutions                  |
| **PROJECT_STRUCTURE.md** | Code structure and technical details         |
| **This file**            | Quick start guide                            |

Start with this file, then check **USAGE.md** for advanced features.

---

## ğŸ’¡ Common Use Cases

### 1. Quick Commit

```powershell
git add .
python main.py --auto-commit
```

### 2. Review Before Committing

```powershell
git add .
python main.py --dry-run
# Review output
python main.py  # Commit if good
```

### 3. Complex Changes

```powershell
git add .
python main.py --verbose
# See detailed breakdown
```

### 4. Save Message for Later

```powershell
git add .
python main.py --dry-run --output commit.txt
# Edit commit.txt if needed
git commit -F commit.txt
```

---

## ğŸ› ï¸ Troubleshooting Quick Fixes

### "No module named 'X'"

```powershell
pip install -r requirements.txt
```

### "CUDA out of memory"

Edit `.env`:

```env
USE_8BIT=true
# Or
DEVICE=cpu
```

### "No staged changes found"

```powershell
git add .
```

### "Model download is slow"

Be patient on first run. The model (~7GB) downloads once and is cached.

### More issues?

See **TROUBLESHOOTING.md**

---

## ğŸ“ Learning Path

1. **Start here** âœ“ You are here!
2. **Run quickstart**: `python quickstart.py`
3. **Try example**: `python tests/example_usage.py`
4. **Use with your code**: `git add . && python main.py`
5. **Read USAGE.md**: Learn all features
6. **Customize**: Edit agents for your needs
7. **Read PROJECT_STRUCTURE.md**: Understand internals

---

## ğŸ¤ Getting Help

1. **Check documentation** in order:

   - This file
   - USAGE.md
   - TROUBLESHOOTING.md

2. **Run diagnostics**:

   ```powershell
   python quickstart.py
   python main.py --verbose
   ```

3. **Test with example**:
   ```powershell
   python tests/example_usage.py
   ```

---

## âœ¨ Features Highlight

- ğŸ¤– **AI-Powered**: Uses OpenChat-3.5 LLM
- ğŸ“ **Conventional Commits**: Follows best practices
- ğŸ”„ **Three-Agent System**: Diff â†’ Summary â†’ Commit
- ğŸ¯ **Accurate**: Analyzes actual code changes
- âš¡ **Fast**: ~5-10 seconds per commit (GPU)
- ğŸ”§ **Customizable**: Extend agents and prompts
- ğŸ **Pure Python**: Easy to understand and modify
- ğŸ“Š **Debug Mode**: See all intermediate outputs
- ğŸ¨ **Colored Output**: Easy to read in terminal
- ğŸ§ª **Tested**: Includes test suite and examples

---

## ğŸ¯ Next Steps

Choose your path:

**New to the project?**
â†’ Run: `python quickstart.py`
â†’ Then: `python tests/example_usage.py`

**Ready to use?**
â†’ Configure: Edit `.env`
â†’ Run: `python main.py`

**Want to customize?**
â†’ Read: `PROJECT_STRUCTURE.md`
â†’ Edit: Files in `agents/` directory

**Having issues?**
â†’ Check: `TROUBLESHOOTING.md`
â†’ Run: `python quickstart.py`

---

## ğŸ“ Quick Reference

| Command                         | Purpose                    |
| ------------------------------- | -------------------------- |
| `python quickstart.py`          | Verify setup               |
| `python main.py`                | Generate commit message    |
| `python main.py --dry-run`      | Preview without committing |
| `python main.py --verbose`      | Show detailed logs         |
| `python main.py --debug`        | Show all outputs           |
| `python main.py --help`         | Show all options           |
| `python tests/example_usage.py` | Run example                |
| `pytest tests/ -v`              | Run test suite             |

---

**Ready to generate amazing commit messages? Let's go! ğŸš€**

```powershell
git add .
python main.py
```

---

_Built with â¤ï¸ using OpenChat-3.5 and Python_
