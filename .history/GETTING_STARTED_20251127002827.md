# ğŸš€ GETTING STARTED

Welcome to the Git Commit AI Pipeline! This guide will get you up and running in **5 minutes** using **Ollama**.

## âš¡ Quick Start (5 Minutes)

### Step 1: Install Ollama

**Windows:**
1. Download from [ollama.com/download](https://ollama.com/download)
2. Run `OllamaSetup.exe`
3. Ollama starts automatically

**macOS/Linux:**
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

### Step 2: Pull OpenChat Model

```powershell
ollama pull openchat:7b
```

This downloads ~4.1GB. Wait for completion.

### Step 3: Install Python Dependencies

```powershell
pip install -r requirements.txt
```

Required packages:
- GitPython
- python-dotenv
- requests
- colorama

### Step 4: Configure (Optional)

The default `.env` is already configured for Ollama!

```powershell
# View current config
python -c "from config import Config; Config.display()"
```

Default settings:
- LLM Mode: `api` (uses Ollama)
- API URL: `http://localhost:11434/v1`
- Model: `openchat:7b`

### Step 5: Test It!

```powershell
# Create a test file
echo "def hello(): print('world')" > test.py

# Stage it
git add test.py

# Generate commit message
python main.py --dry-run
```

**Expected output:**
```
feat: add hello world function in test.py
```

That's it! ğŸ‰ You're ready to use Git Commit AI!

---

## ğŸ“‹ Prerequisites

### Required

- âœ… **Python 3.8+** - Programming language runtime
- âœ… **Git** - Version control system
- âœ… **Ollama** - Local LLM runtime (free!)
- âœ… **8GB+ RAM** - For running OpenChat 7B

### Optional (for better performance)

- ğŸš€ **NVIDIA GPU** - Ollama automatically uses it if available
- ğŸš€ **16GB+ RAM** - For larger models or multiple concurrent requests

---

## ğŸ¯ Why Ollama?

### âœ… Advantages

1. **100% Free & Open Source** - No API costs, ever
2. **Privacy First** - All processing happens locally
3. **Easy Setup** - One-click installation
4. **Optimized Performance** - Faster than raw transformers
5. **Model Management** - Simple commands to install/remove models
6. **GPU Acceleration** - Automatic CUDA/Metal/ROCm support

### ğŸ“Š Performance Comparison

| Method                     | Setup Time | Inference Speed | Privacy | Cost    |
| -------------------------- | ---------- | --------------- | ------- | ------- |
| **Ollama** (Recommended)   | 5 min      | Fast âš¡          | âœ… 100%  | $0      |
| HuggingFace Transformers   | 15 min     | Slow ğŸŒ          | âœ… 100%  | $0      |
| OpenAI API                 | 2 min      | Fast âš¡          | âŒ Cloud | $$$/mo  |
| Local vLLM                 | 20 min     | Very Fast ğŸš€     | âœ… 100%  | $0      |

---

### Step 1: Install Ollama (Already Done! âœ…)

You've already installed Ollama. Verify it's working:

```powershell
# Check Ollama version
ollama --version

# List installed models
ollama list
# Should show: openchat:7b

# Test Ollama
ollama run openchat:7b "Say hello"
# Should generate a response
```

### Step 2: Install Python Dependencies

```powershell
# Make sure you're in the project directory
cd c:\Users\Hp\Downloads\GenAI\code

# Install required packages
pip install -r requirements.txt
```

**What gets installed:**
- `GitPython` - For Git operations
- `python-dotenv` - For configuration
- `requests` - For Ollama API calls
- `colorama` - For colored terminal output

### Step 3: Verify Configuration

```powershell
# Display current configuration
python -c "from config import Config; Config.display()"
```

Expected output:
```
============================================================
CONFIGURATION
============================================================
LLM Mode:          api
API URL:           http://localhost:11434/v1
API Model:         openchat:7b
Repository:
Commit Style:      conventional
Debug Mode:        True
Log Level:         INFO
============================================================
```

### Step 4: Run Verification Script

```powershell
python quickstart.py
```

This checks:
- âœ… Python dependencies installed
- âœ… Git available
- âœ… Ollama running
- âœ… OpenChat model available
- âœ… Configuration valid

### Step 5: Test with Example

```powershell
# Initialize git if needed
git init

# Create a test file
echo "def greet(name): return f'Hello, {name}!'" > greeting.py

# Stage the file
git add greeting.py

# Generate commit message (preview only)
python main.py --dry-run
```

Expected commit message:
```
feat: add greeting function for user salutations
```

---

## ğŸ¯ Understanding the Pipeline Flow

Example Output:

```
====================================================================
   ğŸ¤– Git Commit Writer Pipeline - Powered by OpenChat-3.5
====================================================================

Initializing pipeline...
âœ“ Pipeline initialized

Checking for staged changes...
âœ“ Found staged changes

Running pipeline...

====================================================================
  ğŸ“ GENERATED COMMIT MESSAGE
====================================================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ feat(api): implement user authentication system                â”‚
â”‚                                                                 â”‚
â”‚ - Add JWT token generation and validation                      â”‚
â”‚ - Implement password hashing with bcrypt                       â”‚
â”‚ - Create login and logout endpoints                            â”‚
â”‚ - Add middleware for route protection                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Do you want to commit with this message? (y/n):
```

---

## ğŸ“š Documentation Guide

| Document                 | Purpose                                      |
| ------------------------ | -------------------------------------------- |
| **README.md**            | Project overview, installation, architecture |
| **USAGE.md**             | Detailed usage guide, all CLI options        |
| **TROUBLESHOOTING.md**   | Common issues and solutions                  |
| **PROJECT_STRUCTURE.md** | Code structure and technical details         |
| **This file**            | Quick start guide                            |

Start with this file, then check **USAGE.md** for advanced features.

---

## ğŸ’¡ Common Use Cases

### 1. Quick Commit

```powershell
git add .
python main.py --auto-commit
```

### 2. Review Before Committing

```powershell
git add .
python main.py --dry-run
# Review output
python main.py  # Commit if good
```

### 3. Complex Changes

```powershell
git add .
python main.py --verbose
# See detailed breakdown
```

### 4. Save Message for Later

```powershell
git add .
python main.py --dry-run --output commit.txt
# Edit commit.txt if needed
git commit -F commit.txt
```

---

## ğŸ› ï¸ Troubleshooting Quick Fixes

### "No module named 'X'"

```powershell
pip install -r requirements.txt
```

### "CUDA out of memory"

Edit `.env`:

```env
USE_8BIT=true
# Or
DEVICE=cpu
```

### "No staged changes found"

```powershell
git add .
```

### "Model download is slow"

Be patient on first run. The model (~7GB) downloads once and is cached.

### More issues?

See **TROUBLESHOOTING.md**

---

## ğŸ“ Learning Path

1. **Start here** âœ“ You are here!
2. **Run quickstart**: `python quickstart.py`
3. **Try example**: `python tests/example_usage.py`
4. **Use with your code**: `git add . && python main.py`
5. **Read USAGE.md**: Learn all features
6. **Customize**: Edit agents for your needs
7. **Read PROJECT_STRUCTURE.md**: Understand internals

---

## ğŸ¤ Getting Help

1. **Check documentation** in order:

   - This file
   - USAGE.md
   - TROUBLESHOOTING.md

2. **Run diagnostics**:

   ```powershell
   python quickstart.py
   python main.py --verbose
   ```

3. **Test with example**:
   ```powershell
   python tests/example_usage.py
   ```

---

## âœ¨ Features Highlight

- ğŸ¤– **AI-Powered**: Uses OpenChat-3.5 LLM
- ğŸ“ **Conventional Commits**: Follows best practices
- ğŸ”„ **Three-Agent System**: Diff â†’ Summary â†’ Commit
- ğŸ¯ **Accurate**: Analyzes actual code changes
- âš¡ **Fast**: ~5-10 seconds per commit (GPU)
- ğŸ”§ **Customizable**: Extend agents and prompts
- ğŸ **Pure Python**: Easy to understand and modify
- ğŸ“Š **Debug Mode**: See all intermediate outputs
- ğŸ¨ **Colored Output**: Easy to read in terminal
- ğŸ§ª **Tested**: Includes test suite and examples

---

## ğŸ¯ Next Steps

Choose your path:

**New to the project?**
â†’ Run: `python quickstart.py`
â†’ Then: `python tests/example_usage.py`

**Ready to use?**
â†’ Configure: Edit `.env`
â†’ Run: `python main.py`

**Want to customize?**
â†’ Read: `PROJECT_STRUCTURE.md`
â†’ Edit: Files in `agents/` directory

**Having issues?**
â†’ Check: `TROUBLESHOOTING.md`
â†’ Run: `python quickstart.py`

---

## ğŸ“ Quick Reference

| Command                         | Purpose                    |
| ------------------------------- | -------------------------- |
| `python quickstart.py`          | Verify setup               |
| `python main.py`                | Generate commit message    |
| `python main.py --dry-run`      | Preview without committing |
| `python main.py --verbose`      | Show detailed logs         |
| `python main.py --debug`        | Show all outputs           |
| `python main.py --help`         | Show all options           |
| `python tests/example_usage.py` | Run example                |
| `pytest tests/ -v`              | Run test suite             |

---

**Ready to generate amazing commit messages? Let's go! ğŸš€**

```powershell
git add .
python main.py
```

---

_Built with â¤ï¸ using OpenChat-3.5 and Python_
